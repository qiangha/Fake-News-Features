{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Misinformation Diffusion on Twitter Network during the 2016 US Election with Google Cloud Storage and Pyspark \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Abstract\n",
    "\n",
    "* Dataset\n",
    "\n",
    "* Main\n",
    "\n",
    "    * Preprocessing and fact checking\n",
    "    * Topic analysis\n",
    "    * Analysis of tweet and user level features\n",
    "    * Network Analysis\n",
    "\n",
    "* Distributed Computing Technology Used¶\n",
    "\n",
    "* Conclusion\n",
    "\n",
    "* Limitation and Steps for future research¶\n",
    "\n",
    "* References¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Abstract\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the 2016 US election, Twitter has played an indispensable role in spreading information about the presidential candidates Hillary Clinton and Donald Trump -- both true and false information. It has been shown that during the election links to ​misinformation​--defined as “news stories that present political facts that are demonstrably false or misleading”--were shared more often than popular credible media outlets, such as the New York Times, Fox News, and the Washington Post, combined (Pablo, 2018). Though it remains arguable whether the spread of information on Twitter has a causal effect on the result of the election, it is undoubtable that misinformation has become more and more prevalent and pervasive in our lives and have a serious impact on real-world events. \n",
    "\n",
    "This project hopes to contribute to the ongoing research of fake news detection. Fake news is defined as tweets that contain an url that points to a credible source and true news is defined as tweets that contain an url that points to a fake news website.The aim of this project is to compare fake news and true news in Twitter on both \n",
    "tweet level (e.g time/location of tweets), user level (e.g. favourite count for user) and the linguistic level (topic modelling), and identify characteristics that distinguish fake news from true news. The contribution of the project is in identifying 1 tweet level features, 5 user level features features that are useful in distinguishing fake news and true news. Also the project established that fake news topics more novel and generate greater emotion and fake news tend to use a lot of swear words. This project will help understanding fake news spread among Twitter network and serve as a first step in building models to effectively detect of misinformation on social media. \n",
    "\n",
    "The dataset I used for the anlaysis was very large in size (800GB) in size and requires large storage space and efficient processing methods.. To solve the big data problem, I stored data online using Google Cloud Storage and performed analysis using Pyspark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I will use a dataset collected by Barbera (2018) from Oct 12nd to 01st Nov, 2016. The dataset contains tweets that mentioned Hillary Clinton and Donald Trump from 30 before the election day, Nov 8th, 2016 until 10 days before the election date. In total, there are about 60 million tweets--50 GB of json.gz files （800GB of json file after decompressing. The unzipped files are stored in google cloud storage, available upon request. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A tweet json object is formed of 5 parts: Tweet Object (tweet status), User Object (user info), Entities Object (raw tweet), Extended Entities Object (contains media info), Geo Object (contains geo location of the tweet). A sample tweet can be found at https://gist.github.com/pandafulmanda/4442be1d0208b3b087fe1f61b0a70e75. \n",
    "Tweet schema can be viewed at twitter_schema.ipynb (http://localhost:8888/notebooks/main/twitter_schema.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project is divided into four parts\n",
    "\n",
    "1. preprocessing and fact checking: \n",
    "\n",
    "Methodology:\n",
    "\n",
    "    * Firstly, I preprocessed the tweet json obejcts to select tweet level, user_level information that may be useful in distinguishing fake news and true news. Then I fact checked each tweet and created a new column to store the result. I saved the output to google cloud storage for future use. After that, I conducted explanatory data analysis to examine how many fake or true news were parsed and visiualise the comparision between tweets mentioning Hillary and Trump.\n",
    "    \n",
    "\n",
    "    * For fact checking,I subsetted tweets that contain links to external news websites. I then classified the individual links shared on Twitter as fake or true based on a combined list of domains (see domains.csv) that were producing mostly misformation compiled by Zimdars (2016)--used in other misinformation studies--and a most recent list provided by ​Guess, Nagler, and Tucker ​(2018). If the tweet is true, it has a score 1. If the tweet is false, it has a score -1.If the tweet does not contain an url, it is classified as None and if it contains an url not in true or fake news domain, it has a score 0.  \n",
    "    \n",
    "    \n",
    "Result:\n",
    "\n",
    "    * I found that number of fake news are much bigger than the number of true news on any day, and the discrepancy in number seems to be growing as we are approaching the election day. The ratio of fake to true news for Hillary was around 4:1 while the ratio for trump was much higher around 6:1.\n",
    "    \n",
    "\n",
    "    * There were more true news mentioning Hillary than Trump, roughly 2 times as many throughout the period. For the fake news, the number of fake news mentioning trump had been higher than that mentioning hillary until about 28th Oct when the number of fake news mentioning hillary exceeds that mentioning Trump. After research,I found the reason for the increase in fake news mentioning Hillary was probably that on 28th Oct, FBI Director at the time, James Comey sent a letter to Congress saying he had “learned of the existence of emails that appear to be pertinent to the investigation” into the private email server that Clinton used as secretary of state. \n",
    "    \n",
    "#####    Please see fact_checking.ipynb (http://localhost:8888/notebooks/main/fact_checking.ipynb) for implementation. \n",
    "domains.csv can be accessed at http://localhost:8888/edit/main/domains.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Topic analysis\n",
    "\n",
    "Methodology:\n",
    "\n",
    "    * I used Latent Dirichlet Allocation models to model the topics in twitter. For the 20 day periods, I ran the model to extract the top features to compare topics of true news and fake news and analyse the differences of topics and top features for fake and true news. Latent Dirichlet Allocation is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.Each document may be viewed as a mixture of various topics where each document is considered to have a set of topics that are assigned to it via LDA. This is identical to probabilistic latent semantic analysis (pLSA), except that in LDA the topic distribution is assumed to have a sparse Dirichlet prior.  \n",
    "\n",
    "    * By examing the top features identified by the LDA model and searching them on Google, I analysed the top three identiable topics for true news and fake news mentioning Hillary each day. \n",
    "    \n",
    "Result:\n",
    "    \n",
    "    1. We can clearly see fake news topics can be divided into two categories: \n",
    "    * Those are related to true news happening at the time.  \n",
    "    * Videos/sayings created to express violence/hatry/uglify people\n",
    " \n",
    "    Examples for the first category includes those related to Wikileak founder (claiming he is dead/he has killed someone ), those related to problems in election voting (a breaking down of a voting machine led to the claim that voting is rigged). Examples for the second category includes video about President Obama and George Soros killing dogs. Actress Susan saradon was involved in drug, murder, sex.\n",
    "    \n",
    "    2. The top features of fake news are more novel and generate greater emotion than the ones in true news. Fake news constantly use words like killing, raping, smuggling that sounds horrifying. Also, fake news use a lot of sear words, like fuck,shit, etc. On the contrary, true news seem to be pretty to the point. There are few words generating emotion. For example, ['cernovich' 'hillarygropedme' 'attention' 'year' 'state' 'special' 'gave' 'old' 'bill' 'quake' 'dept' 'locker' 'room' 'offended' 'silly'] and ['hypocrisy' 'call' 'penny' 'sander' 'twitter' 'tcovnyselswfh' 'caymanstaxdodge' 'supporter' 'overheard' 'standard' 'bigoted' 'campaign'] does not have strong/novel words or swearing words.\n",
    "\n",
    "#### Please see topic_modelling.ipynb (http://localhost:8888/notebooks/main/topic_modelling.ipynb) for implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Analysis of tweet and user level features\n",
    "\n",
    "Methodology:\n",
    "\n",
    "* I extracted tweet and user level characteristics and checked if they can be used as features to distinguish true or fake news. For tweet level, the features I considered were geo (the place of the tweet), created_at(the time of the tweet). For user_level, the features I considered were user verification, account creation time, favourite_count,friends_count, follower_count, statues_count.\n",
    "\n",
    "* For categorical variables like geo, created_at, I calculated the ratio of fake news to true news per category per date and plotted the result.\n",
    "\n",
    "* For continuous variables, like user_favourite_count, I built several logistic regression models with or without a given feature and compare model performance to select the features that are most relevant in classifying the news on Twitter.\n",
    "\n",
    "Result:\n",
    "\n",
    "    Tweet level features:\n",
    "\n",
    "    * The city where the tweet was sent is significant in classifying tweets. Different cities exert very different fake to true news ratio. For majority days of the 21 day period, most cities seem to produce more true news than fake news while some cities seem to produce more fake news than true news.\n",
    "    * Hour when the tweeted was created cannot be used as a feature to distinguish fake news from true news. The distribution of ratio of fake news to true news for any hour appear to be very similiar throughout the 21 days period.\n",
    "\n",
    "    User level features:\n",
    "    * User verification is an important feature in classifying news. For tweets mentioning Hillary ot Trump, it is clear those produced by unverified users have a far higher fake to true news ratio than those produced by verified users.\n",
    "\n",
    "    * We can use year of creation (whether created just before a major political event or not) as a factor to classify political fake news. The number of fake news published by accounts created in 2016 is far larger (about 3 times) than that created by account in any other year.\n",
    "\n",
    "    * Friends_count is an important feature in classifying news. Also, any pair of favourite_count, follower_count,statues_count would also help (any third one is redudant). For the logistic regression model that uses these 4 features alone, we can an areaUnderROC of 0.57 and an area under PR of 0.81.\n",
    "\n",
    "#### Please see user_tweet_level_features.ipynb for implementation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Computing Technology Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data for the project is very large in size, I do not have the RAM to process all the files on my laptop and it would be very slow. So I have decided to employ distributed computing systems to speed up the processing. Below I will describe the technology used for each task and compare it to its rivals.\n",
    "\n",
    "#### Please see distributed computing technology.ipynb (http://localhost:8888/notebooks/main/distributed%20computing%20technology.ipynb) for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I compared fake news and true news in Twitter on both tweet level (e.g time/location of tweets), user level (e.g. favourite count for user) and the linguistic level (topic modelling), and identified characteristics that distinguish fake news from true news. \n",
    "\n",
    "Below I will summarise the results and speculate on why the features are distinguishing fake news from true news.\n",
    "\n",
    "I successfully identified 1 tweet level features, 5 user level features features that are useful in distinguishing fake news and true news. \n",
    "\n",
    "* The Tweet level feature is the city where the tweet was created. Different cities exert very different fake to true news ratio. For majority days of the 21 day period, while most cities produce more true news than fake news, suprisingly, some cities seem to produce more fake news than true news.\n",
    "\n",
    "* User level features are:\n",
    "    * User verification, tweets produced by verified users are far more likely to be true. Verified users are musicians, singers, who are more educated (better at discovering fake news) and are watched by the public (no incentive to spread fake news)\n",
    "\n",
    "    * Year of creation of the account, account created in the year of a major political event more likely to produce fake news than those created in other uears. Some accounts may be created for the purpose of spreading fake news.\n",
    "\n",
    "    * Friends_count, any pair of favourite_count, follower_count,statues_count. For the logistic regression model that uses these 4 features alone, we can an areaUnderROC of 0.57 and an area under PR of 0.81. The reason why friends_count is important i guess is there are bots/agencies who maintain a lot of friends for the purpose of spreading fake news (need further analysis).\n",
    "\n",
    "Through topic modelling, I figured out fake news can be divided into two categories:\n",
    "* Those are related to true news happening at the time.  \n",
    "* Videos/sayings created to express violence/hatry/uglify people\n",
    "\n",
    "I also established that fake news topics more novel and generate greater emotion and fake news tend to use a lot of swear words. Novelty and swear words draw people's attention and generate more clicks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitation and Steps for future research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the user object, I was only given limited information, such as favorite counts but not the information about who they are. This limited my analysis of user characteristics (age of user may be important). However, using matching techniques could have enabled me to obtain more user information.\n",
    "\n",
    "Furthermore, the scope was limited to fake news classification method based on urls; the findings might not represent characteristics of misinformation spread that does not contain urls. My results are also confined to the topic of Clinton and Trump during a 20-day period. Widening the topics of fake news and time period of diffusion might lead to more robust results.\n",
    "\n",
    "Another aspect that one can distinguish fake news from true news is network analysis.  By analysing network propertities such as transitivity, average path length, onro find difference between fake news and true news. I originally planned to build two directed retweet networks of users, one for true news, one for fake news. Each node of the graph is a user in Twitter. There is an edge between two nodes if an user has shared at least a true/fake news from another user. But I run out of time. \n",
    "\n",
    "The object of the project was only to identify features that may help in distinguishing fake news from true news. Future researchers could build models using features identified or try building end to end neural networks without feature engineering to see how well tweets can be classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweeter json explained\n",
    "https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object\n",
    "\n",
    "Sample json\n",
    "https://gist.github.com/pandafulmanda/4442be1d0208b3b087fe1f61b0a70e75\n",
    "\n",
    "Fake News Domain 1 (Melissa Zimdars. False, Misleading, Clickbait-y, and Satirical “News” Sources. Nov, 2016. Accessed on Jan,\n",
    "2019, from)\n",
    "https://d279m997dpfwgl.cloudfront.net/wp/2016/11/Resource-False-Misleading-Clickbait-y-and-Satirical-%E2%80%9CNews%E2%80%9D-Sources-1.pdf​.\n",
    "\n",
    "Fake News Domain 2 (Andrew Guess, Jonathan Nagler, and Joshua Tucker.) Less than you think: Prevalence and predictors of fake\n",
    "news dissemination on Facebook. S​cience Advances​. 09 Jan 2019: Vol. 5, no. 1, eaau4586.\n",
    "\n",
    "Google Storage\n",
    "https://en.wikipedia.org/wiki/Google_Storage\n",
    "\n",
    "How Google Cloud Storage offers strongly consistent object listing thanks to Spanner\n",
    "https://cloud.google.com/blog/products/gcp/how-google-cloud-storage-offers-strongly-consistent-object-listing-thanks-to-spanner\n",
    "\n",
    "Spanner explained\n",
    "https://storage.googleapis.com/pub-tools-public-publication-data/pdf/acac3b090a577348a7106d09c051c493298ccb1d.pdf\n",
    "\n",
    "GraphFrames\n",
    "https://pages.databricks.com/rs/094-YMS-629/images/02-Dave.pdf\n",
    "\n",
    "Spark MLlib\n",
    "https://arxiv.org/pdf/1505.06807.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
